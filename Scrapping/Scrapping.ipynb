{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af223ca9-0481-4a7b-9b38-bdf09bf558cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set working path\n",
    "path = '/Users/martinbogaert/Desktop/NBA Data Analysis/2022-2023_Awards_Project_clean/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e375b34c-96d6-4820-b6c1-db04aa9dd43a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## A. Awards scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c563ee-4f4c-42eb-92f2-e66f8830d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function scraps input award history for given timerange\n",
    "def award_history(aw, start, end = 2022):\n",
    "    \n",
    "    year = list(range(start, end+1))\n",
    "\n",
    "    dfs = []\n",
    "    for yr in year:\n",
    "\n",
    "        url = f'https://www.basketball-reference.com/awards/awards_{yr}.html'\n",
    "        page = requests.get(url)\n",
    "        \n",
    "    #    with open(path + f'Scrapping/{aw} yearly data/{yr}.html', 'w+') as file:\n",
    "       #     file.write(page.text)\n",
    "       #     file.close()\n",
    "        \n",
    "    #    if yr < 1976 and yr > 1971:\n",
    "       #     table = page.text.split(f'<div class=\"table_container\" id=\"div_nba_{aw}\">')[1].split('</table>')[0] + '</table>'\n",
    "        \n",
    "        table = page.text.split(f'<div class=\"table_container\" id=\"div_{aw}\">')[1].split('</table>')[0] + '</table>'\n",
    "           \n",
    "        soup = BeautifulSoup(table, 'html')\n",
    "        soup.find('tr', class_ = 'over_header').decompose()\n",
    "        \n",
    "        year_df = pd.read_html(str(soup))[0]\n",
    "        year_df['Year'] = len(year_df) * [yr]\n",
    "        \n",
    "        dfs.append(year_df)\n",
    "        \n",
    "        clear_output(wait = True)\n",
    "        print(str(yr) + ' / 2022')\n",
    "\n",
    "    DF = pd.concat(dfs)\n",
    "\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c604d7-8798-425c-afe6-0db3e62697a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### MVP history scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "884b6806-c1a5-48ba-9aaa-92451e8a379e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 / 2022\n"
     ]
    }
   ],
   "source": [
    "# Most Valuable Player votes scrapping\n",
    "mvp = award_history('mvp', 1978)\n",
    "mvp = mvp.reset_index(drop = True)[['Player', 'Year', 'Share']]\n",
    "mvp.to_csv(path + 'Scrapping/mvp_history.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfc4588-4f56-48eb-a7e5-392178c21409",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ROY history scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b803144-dc15-43f3-9b6b-1d2b248dcca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 / 2022\n"
     ]
    }
   ],
   "source": [
    "# Rookie of the Year votes scrapping\n",
    "roy = award_history('roy', 1978)\n",
    "roy = roy.reset_index(drop = True)[['Player', 'Year', 'Share']]\n",
    "roy.to_csv(path + 'Scrapping/roy_history.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894c9089-9575-4eef-82ed-c43d9fade62e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DPOY history scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "446e637b-36ee-4518-80ae-652b09f0dc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 / 2022\n"
     ]
    }
   ],
   "source": [
    "dpoy = award_history('dpoy', 1983)\n",
    "dpoy = dpoy.reset_index(drop = True)[['Player', 'Year', 'Share']]\n",
    "dpoy.to_csv(path + 'Scrapping/dpoy_history.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c53351-3fed-4602-85b8-d7a8f05ea6d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SMOY history scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86257c03-3bc4-4eb4-831b-4d1c8acdff17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 / 2022\n"
     ]
    }
   ],
   "source": [
    "# 6th Man of the Year votes scrapping\n",
    "smoy = award_history('smoy', 1984)\n",
    "smoy = smoy.reset_index(drop = True)[['Player', 'Year', 'Share']]\n",
    "smoy.to_csv(path + 'Scrapping/smoy_history.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5efe4e-57a4-4b10-a712-920b63563fae",
   "metadata": {},
   "source": [
    "### MIP history scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5871f00-35d7-4111-9dcb-4af65f7813e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 / 2022\n"
     ]
    }
   ],
   "source": [
    "# Most Improved Player votes scrapping\n",
    "mip = award_history('mip', 1988)\n",
    "mip = mip.reset_index(drop = True)[['Player', 'Year', 'Share']]\n",
    "mip.to_csv(path + 'Scrapping/mip_history.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bf89a3-2f70-4c63-a4cb-df28c7bd262f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## B. Players scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "504d773d-7461-4566-be28-ecc14d8a03ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to replace traded player with a single row, team is the last he played on\n",
    "def single_player(df):\n",
    "    if len(df) == 1: # If player played for a single team, do nothing\n",
    "        return df\n",
    "    else: # If player has moved, return total stats with last team\n",
    "        row = df[df['Tm'] == 'TOT'].copy()\n",
    "        row['Tm'] = str(df['Tm'].iloc[-1])\n",
    "        return row\n",
    "\n",
    "# Function to scrape players stats (per game & advanced)\n",
    "def stat_year(yr):\n",
    "    \n",
    "    Types = ['per_game', 'advanced']\n",
    "    dfs = []\n",
    "    for Type in Types: # loop for both type of stats\n",
    "    \n",
    "        url = f'https://www.basketball-reference.com/leagues/NBA_{yr}_{Type}.html'\n",
    "        page = requests.get(url)\n",
    "\n",
    "        with open(path + f'SCrapping/player yearly data/{yr}.html', 'w+') as file:\n",
    "            file.write(page.text)\n",
    "            file.close()\n",
    "\n",
    "        soup = BeautifulSoup(page.content, 'html')\n",
    "        table = soup.find('table')\n",
    "\n",
    "        stats = pd.read_html(str(table))[0]\n",
    "        stats = stats[stats['Rk'] != 'Rk'].reset_index(drop = True) # Drop intra-data headers\n",
    "        del stats['Rk']\n",
    "        \n",
    "        dfs.append(stats)\n",
    "    \n",
    "    # Deal with stats which appear in both per game and advanced data\n",
    "    col_pg = list(dfs[0]) # Store columns in per game data\n",
    "    col_pg.remove('Player'); col_pg.remove('Tm') # Remove merge columns\n",
    "    col_adv = list(dfs[1]) # Store columns in advanced data\n",
    "    unique_cols = [x for x in col_adv if x not in col_pg] # Keep advanced columns if they are unique\n",
    "    \n",
    "    # Merge on player and team\n",
    "    DF = pd.merge(dfs[0], dfs[1][unique_cols], on = ['Player', 'Tm'])\n",
    "    DF['Year'] = len(DF) * [yr] #Â Keep track of year\n",
    "    del DF['Unnamed: 19']\n",
    "    del DF['Unnamed: 24']\n",
    "    \n",
    "    DF = DF.groupby(['Player']).apply(single_player) # Apply single player function to each player\n",
    "    DF = DF.reset_index(drop = True)\n",
    "    \n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ead9c3e3-13c0-444e-9dad-10d051451f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 / 2022\n"
     ]
    }
   ],
   "source": [
    "# Run function for all years\n",
    "years = list(range(1978, 2023))\n",
    "dfs = []\n",
    "for yr in years:\n",
    "    dfs.append(stat_year(yr))\n",
    "    clear_output(wait = True)\n",
    "    print(str(yr) + ' / 2022')\n",
    "\n",
    "data = pd.concat(dfs)\n",
    "data['Player'] = data['Player'].str.replace('*', '', regex = False) # Clean player name column\n",
    "data = data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27b63b5e-9cf3-4a89-a091-3559ba44b941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% WSB 1996-1997 ...\n"
     ]
    }
   ],
   "source": [
    "# Add individual ORtg and DRtg (can only be found in team data)\n",
    "dfs_rtg = []\n",
    "for i, tm_yr in enumerate(data.groupby(['Tm','Year']).groups.keys()):\n",
    "    \n",
    "    prog = round(100 * (i+1) / len(data.groupby(['Tm','Year']).groups.keys()), 2)\n",
    "    print(f'{prog}% {tm_yr[0]} {tm_yr[1]-1}-{tm_yr[1]} ...')\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    url = f'https://www.basketball-reference.com/teams/{tm_yr[0]}/{tm_yr[1]}.html'\n",
    "    page = requests.get(url)\n",
    "\n",
    "    table = page.text.split(f'<div class=\"table_container current\" id=\"div_per_poss\">')[1].split('</table>')[0] + '</table>'\n",
    "    soup = BeautifulSoup(table, 'html')\n",
    "    \n",
    "    data_rtg = pd.read_html(str(soup))[0]\n",
    "    data_rtg['Tm'] = len(data_rtg) * [tm_yr[0]]\n",
    "    data_rtg['Year'] = len(data_rtg) * [tm_yr[1]]\n",
    "\n",
    "    data_rtg = data_rtg.rename(columns = {'Unnamed: 1' : 'Player'})[['Player','Tm','Year','ORtg','DRtg']]\n",
    "    dfs_rtg.append(data_rtg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bedfc24e-44a4-4e84-8af2-b92552a4dbfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_rtg = pd.concat(dfs_rtg).rename(columns = {'ORtg':'ORtg/100', 'DRtg':'DRtg/100'})\n",
    "data_rtg['Player'] = data_rtg['Player'].str.replace('*', '', regex = False) # Clean player name column\n",
    "data = data.merge(data_rtg, on = ['Player','Year','Tm'], how = 'inner')\n",
    "\n",
    "data.to_csv(path + 'Scrapping/player_data.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6b6ba4-8b3e-4d96-9440-f9bba6f648b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## C. Teams scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c55f615-def3-48ec-92cb-f33330fc2cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to format team name post-2022, get rid of parentheses with seed following team name\n",
    "#def team_name(tm, sd):\n",
    " #   l = []\n",
    " #   for team, seed in zip(tm, sd):\n",
    " #       if len(str(seed)) == 1:\n",
    " #           l.append(team[:-4])\n",
    " #       else:\n",
    "  #          l.append(team[:-5])\n",
    "  #  return l\n",
    "###  NO LONGER FORMATTED AS SUCH ###\n",
    "\n",
    "# Function to scrape team stats\n",
    "def team_history(yr):\n",
    "    \n",
    "    # Scrape team standings\n",
    "    url = f'https://www.basketball-reference.com/leagues/NBA_{yr}.html'\n",
    "    page = requests.get(url)\n",
    "    \n",
    "    with open(path + f'Scrapping/team yearly data/sds_{yr}.html', 'w+') as file:\n",
    "            file.write(page.text)\n",
    "            file.close()\n",
    "    \n",
    "    soup = BeautifulSoup(page.content, 'html')\n",
    "    \n",
    "    # Decompose all headers, 3 by conference\n",
    "    for i in list(range(0,6)):\n",
    "        if soup.find('tr', class_='thead') is not None:\n",
    "            soup.find('tr', class_='thead').decompose()\n",
    "\n",
    "    # Eastern conference DataFrame\n",
    "    table_E = soup.find('table', id = 'divs_standings_E')\n",
    "    teams_E = pd.read_html(str(table_E))[0]\n",
    "    teams_E = teams_E.rename(columns = {'Eastern Conference': 'Team'})\n",
    "    # Western conference DataFrame\n",
    "    table_W = soup.find('table', id = 'divs_standings_W')\n",
    "    teams_W = pd.read_html(str(table_W))[0]\n",
    "    teams_W = teams_W.rename(columns = {'Western Conference': 'Team'})\n",
    "    # Calculate seeds\n",
    "    teams_E['Seed'] = [len(teams_E[teams_E['W/L%'] > wl])+1 for wl in teams_E['W/L%']]\n",
    "    teams_W['Seed'] = [len(teams_W[teams_W['W/L%'] > wl])+1 for wl in teams_W['W/L%']]\n",
    "    teams_E = teams_E.sort_values('Seed'); teams_W = teams_W.sort_values('Seed') # Sort DataFrames by seed\n",
    "    # Assemble league-wise table\n",
    "    teams = pd.concat([teams_E, teams_W])\n",
    "\n",
    "    # Data cleaning\n",
    "    del teams['GB']\n",
    "    teams['Team'] = teams['Team'].str.replace('*','', regex = False)\n",
    "    teams['Year'] = len(teams) * [yr] # Keep track of year\n",
    "    \n",
    "    # Scrape team ratings\n",
    "    url = f'https://www.basketball-reference.com/leagues/NBA_{yr}_ratings.html'\n",
    "    page = requests.get(url)\n",
    "\n",
    "    with open(path + f'Scrapping/team yearly data/rtg_{yr}.html', 'w+') as file:\n",
    "            file.write(page.text)\n",
    "            file.close()\n",
    "    \n",
    "    soup = BeautifulSoup(page.content, 'html')\n",
    "    soup.find('tr', class_='over_header').decompose()    \n",
    "    table = soup.find('table')\n",
    "    ratings = pd.read_html(str(table))[0][['Team', 'MOV', 'ORtg', 'DRtg', 'NRtg', 'MOV/A', 'ORtg/A', 'DRtg/A', 'NRtg/A']]\n",
    " \n",
    "    # Deal with Charlotte Hornets name problem\n",
    "    ratings['Team'] = ratings['Team'].str.replace('Charlotte Hornets\\xa0', 'Charlotte Hornets')\n",
    "    teams['Team'] = teams['Team'].str.replace('Charlotte Hornets\\xa0', 'Charlotte Hornets')\n",
    "\n",
    "    # Merge standings and ratings\n",
    "    teams = teams.merge(ratings, on = 'Team', how = 'outer')\n",
    "    teams = teams.reset_index(drop = True)\n",
    "\n",
    "    return teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "004c5419-4f73-40c2-a1cd-d2afbe93c74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 / 2022\n"
     ]
    }
   ],
   "source": [
    "# Scrape teams data for all years\n",
    "years = list(range(1978, 2023))\n",
    "dfs = []\n",
    "for yr in years:\n",
    "    dfs.append(team_history(yr))\n",
    "    clear_output(wait = True)\n",
    "    print(str(yr) + ' / 2022')\n",
    "    \n",
    "data_tm = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fe90426-6b88-48d6-8a86-4b538224ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_dic = {'Syracuse Nationals': 'SYR','Buffalo Braves': 'BUF','New York Nets': 'NYN','Cincinnati Royals': 'CIN','Kansas City-Omaha Kings': 'KCO',\n",
    "    'Capital Bullets': 'CAP','Sacramento Kings': 'SAC','Seattle SuperSonics': 'SEA','Los Angeles Clippers': 'LAC','Washington Wizards': 'WAS',\n",
    "    'New Orleans/Oklahoma City Hornets': 'NOK','Phoenix Suns': 'PHO','New Jersey Nets': 'NJN','Washington Bullets': 'WSB','Boston Celtics': 'BOS',\n",
    "    'Golden State Warriors': 'GSW','Denver Nuggets': 'DEN','Vancouver Grizzlies': 'VAN','Orlando Magic': 'ORL','Chicago Bulls': 'CHI','Utah Jazz': 'UTA',\n",
    "    'Toronto Raptors': 'TOR','Los Angeles Lakers': 'LAL','Portland Trail Blazers': 'POR','Memphis Grizzlies': 'MEM','Miami Heat': 'MIA',\n",
    "    'New Orleans Hornets': 'NOH','San Diego Rockets': 'SDR','Atlanta Hawks': 'ATL','Oklahoma City Thunder': 'OKC','Philadelphia Warriors': 'PHW',\n",
    "    'Milwaukee Bucks': 'MIL','New Orleans Jazz': 'NOJ','San Antonio Spurs': 'SAS','Charlotte Hornets': 'CHO','Brooklyn Nets': 'BRK',\n",
    "    'Cleveland Cavaliers': 'CLE','San Diego Clippers': 'SDC','San Francisco Warriors': 'SFW','Rochester Royals': 'ROC','Philadelphia 76ers': 'PHI',\n",
    "    'Houston Rockets': 'HOU','Fort Wayne Pistons': 'FTW','Dallas Mavericks': 'DAL','New York Knicks': 'NYK','Kansas City Kings': 'KCK',\n",
    "    'Indiana Pacers': 'IND','St. Louis Hawks': 'STL','Baltimore Bullets': 'BAL','Detroit Pistons': 'DET','Minnesota Timberwolves': 'MIN','New Orleans Pelicans': 'NOP',\n",
    "    'Chicago Packers': 'CHP','Charlotte Bobcats': 'CHA','Chicago Zephyrs': 'CHZ','Minneapolis Lakers': 'MNL','Charlotte Hornets\\xa0': 'CHO'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4459b23f-4dbe-4e5c-b04b-fd63a4145b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tm = []\n",
    "for yr, tm in zip(data_tm['Year'], data_tm['Team']):\n",
    "    if tm == 'Charlotte Hornets' and yr < 2015:\n",
    "        Tm.append('CHH')\n",
    "    else:\n",
    "        Tm.append(team_dic.get(tm))\n",
    "data_tm['Tm'] = Tm    \n",
    "data_tm = data_tm.reset_index(drop = True)\n",
    "data_tm.to_csv(path + 'Scrapping/team_data.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c834f0-9fb9-4600-9346-f92fb1dc271c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa3b1e-ebd5-45fb-8085-71d89e751a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c2a289-cd48-4bbf-ab70-0cdc21fbf928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('nbaenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "d55ac86caef0df3b44b520ee76b358d306ee1b07c7e8d9d6f10c3bf07051bac8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
